表2は、私たちが得た最良の結果を示しています。

異なる列は、問題のクラス、使用された手法、ネットワークのトポロジー（⇒ #L：ラベル内のユニット数、⇒ #H：表現のためのユニット数）、トレーニングパラメータ（⇒ η：学習パラメータ、⇒ μ：モーメンタム）、パフォーマンス（⇒ %Tr./%Ts. トレーニング/テストセットの用語が正しく分類された割合）、およびこれらの結果を達成するために必要な学習エポック数を示しています。

シミュレーションは、平均ケースでパフォーマンスをわずかに異なるパラメータによって改善するために、2〜3回の再スタートで実行されました。

したがって、パラメータの最適化により、結果をさらに改善することが可能であるはずです。

私たちは、各問題インスタンスに対して、オンラインモード（⇒ ■）とバッチモード（⇒ □）でBPTSを適用し、比較しました。オンラインモードでは、トレーニングセットは毎エポック同じ順序で提示されました。

唯一の学習パラメータ η、モーメンタム μ = 0.6、および唯一の転送関数 tanh が、全体の三層ネットワークアーキテクチャを通じて使用されました。

ネットワークの重みは、[−1.0, 1.0] の範囲の値でランダムに初期化されました。

私たちは二クラスの決定問題を考慮していたため、出力ユニットは負/正のメンバーシップに対して −1.0/1.0 の値で学習されました。

分類パフォーマンスの測定は、決定境界を0に固定して計算されました。

BPTSの性能は、LRAAM分類器（LRAAMC）アーキテクチャ（⇒ △）と共にリストされています。

LRAAMCの結果が利用可能な場合は、特別な動的パターン選択戦略を用いてネットワークトレーニングを行い、LRAAM（⇒ η）と分類器（⇒ ε）に異なる学習パラメータを適用しています。

分類結果（およびこれらの結果を達成するために必要な少ない隠れユニット数）は、lblocc1 long、inst4、およびinst7（トレーニングデータおよびテストデータで100％）が非常に容易な性質を持つことを示唆している一方で、termocc2は将来のアプローチのための真の試金石と見なされるかもしれません。

我々の提案するBPTSを使用したアーキテクチャは、LRAAMCアプローチよりもほぼ同等か、やや優れた分類性能をもたらします。しかし、これは桁違いに少ない隠れユニットを使用するトポロジーと、桁違いに少ないトレーニングエポックで同じパフォーマンスに収束する学習手順によって達成されています。

複雑さの考慮に加え、現在の実験結果に基づくと、BPTSバッチはBPTSオンラインに対して有意な利点を持たないように見えます（セクション2.4.3参照）。

BPTSがネットワークのサイズや学習手順の収束に関してLRAAMCアプローチより優れているのはなぜでしょうか？明らかに、LRAAMCは独自の表現を開発する追加のタスク、すなわちエンコード・デコード誤差を最小化するタスクを解決する必要があります（表2の% Dec.-Enc.参照）。

これは分類問題を解決するよりもはるかに難しいかもしれません。さらに、分類器からの誤差がLRAAMCの構造を通じて再帰的に伝播されないため、正確な勾配は計算されず、我々のアプローチとは対照的に、部分項の表現は親に関する分類タスクに直接最適化されていません。

前述のように、構造の表現は我々のアプローチにおいて推論タスクに最適に調整されています。

図4は、lblocc1 longの用語の表現を示しており、BPTSによるバッチモードでのトレーニングが80回と108回のエポック後に、隠れユニット2つで開発されたものです。

BPTSによるトレーニングが長く続くほど、2つのクラスの表現が表現空間の2つの異なる領域に引き裂かれていく様子が見られます。次に、分離境界（⇒ SB）（5本の平行な傾斜線で示され、tanh(x1w1 + x2w2 + Θ) = {-0.8, -0.4, 0, 0.4, 0.8} によってマークされています）はわずかに回転し、互いに近づいています。

108エポック後、左上の隅に1つの用語表現が残り、1つの誤分類された構造と99.61％のトレーニング精度および100％のテスト精度を達成しました。
