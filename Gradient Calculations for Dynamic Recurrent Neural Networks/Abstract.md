私たちは、隠れユニットを持つリカレントニューラルネットワークの学習アルゴリズムを調査し、さまざまな手法を共通のフレームワークに統合します。

固定ポイント学習アルゴリズム、具体的にはリカレントバックプロパゲーションや決定論的ボルツマンマシン、そして非固定ポイントアルゴリズム、具体的にはバックプロパゲーションスルータイム、Elmanの履歴カットオフ、Jordanの出力フィードバックアーキテクチャを論じます。

隣接方程式を使用した前方伝播やその変形、オンライン技術についても検討します。

多くの場合、統一されたプレゼンテーションがさまざまな種類の一般化につながります。

連続時間ニューラルネットワークの利点と欠点を、クロック付きのものと対比して論じ、連続時間およびリカレントニューラルネットワークのトレーニング、使用、およびシミュレーションに関する「トリック」のいくつかを紹介します。

いくつかのシミュレーションを提示し、最後に計算の複雑さや学習速度の問題に対処します。