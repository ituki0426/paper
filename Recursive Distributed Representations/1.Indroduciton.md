# 1.Introduction

接続主義の高次認知タスク（自然言語処理など）への応用における主要な障害の一つは、その表現の不十分さです。

これまでのところ、局所的および分散された表現は、AIで伝統的に使用されてきた機構増や、グラフ、リスト、スタックのような階層的なデータ構造を捕捉するには不適切でした。

この制限は、純粋な接続主義がこの領域でやや満足のいかないシステムを生成した事実に現れています。

例えば、埋め込み構造なし（文の入れ子になった複雑な構造を扱えない）で固定長の文のパーサー（決まった長さの文だけを解析できるシステム）を生成するに留まっています。

実際、コネクショニズムに対する最近の攻撃のいくつかは、まさに表現の妥当性の問題に向けられています。

例えば、Minsky & Papert [10] によると、1970年代にAIが知識表現に焦点を当てなければならなくなった原因は、「少なくとも潜在的にXを表現するための内部構造やモデルを持たない限り、いかなる機械もXを認識できない」という原則によるものです (p. xiii)。」

Fodor と Pylyshyn [11] によるコネクショニズムに対する批判は、コネクショニズムがX（Xは構成要素の構造を持つ文法的なもの）の表現の潜在能力すら持っていないという信念に基づいています。
構成的なシンボル構造が重要であることに完全に同意した上で、この論文では、それらのためにコンパクトな分散表現を発見できるコネクショニストアーキテクチャを示します。

したがって、思考過程の（意味的な）「体系性」を示すことはできません。


RAAM は、非定常環境におけるバックプロパゲーション[12]を用いて、固定ヴァレンス木（各ノードが持つ子ノードの数（ヴァレンス、すなわち分岐の数）が一定である木構造です。）のすべての内部ノードを表すパターンを作り出します。

（バックプロパゲーションは訓練データが静的で固定されている前提で使用されますが、非定常環境では、データや条件が時間経過と共に変化し、ネットワークが新しい状況に適応する必要があります。このような環境では、モデルがその変化に対応できるように、動的に学習を続けることが求められる。）

＝RAAM（Recursive Auto-Associative Memory）は固定された状況ではなく、常に変化するデータや条件に対しても有効な表現パターンを学習することが目標

さらに、発見された表現は、単に古典的な連結型データ構造のコネクショニスト実装にとどまらず、実際には新しい、興味深い、そして潜在的に非常に有用なものです。

本論文の残りは以下のように構成されています。コネクショニスト表現スキームに関する背景を述べた後、RAAMアーキテクチャを説明し、いくつかの実験結果を提示します。最後に、このアーキテクチャの生成能力についての議論と、新しい表現およびその潜在的な応用に関する分析を行います。


# 1.1　Background: Connectionist Representations

通常のコンピュータプログラムは、配列やリストのような逐次データ構造を基本的な要素として長い間使用してきました。

さらに、これらのシーケンスの内容は他のシーケンスのアドレスになりうるという「アドレス」の概念が組み込まれているため、コンピュータプログラムが木構造やグラフ構造を表現し操作することも非常に簡単です。

しかし、リストや木構造を表現することはコネクショニストネットワークにとって簡単ではありません。

なぜなら、コネクショニストネットワークは隣接するメモリセルやランダムにアドレス指定されたメモリセルを使用せず、新しいユニットをリアルタイムで動的に作成することもできないからです。

現代のコネクショニズムにおける初期の研究のいくつかは、セマンティックネットワークとニューラルネットワークの間に不適切な類推を行いました。

（セマンティックネットワークは、概念間の論理的関係を表現するために使われる構造です。一方、ニューラルネットワークは、生物学的な脳の神経細胞を模倣して構築されており、重み付きのパス（経路）を通じて「活性化エネルギー」が流れる仕組みになっています。初期の研究では、これら二つのネットワークを同一視し、類似の仕組みだと考えられてしまうことがありました。

しかし、この類推は適切ではありませんでした。セマンティックネットワークは概念間の明示的な論理関係を扱うのに対し、ニューラルネットワークは重み付き経路を通じた非線形的な情報処理を行うものであり、基本的なメカニズムが大きく異なるからです。したがって、セマンティックネットワークとニューラルネットワークの違いを無視したり、過剰に類似性を主張することは不適切だったという意味になります。）


前者のリンクは概念間の論理的な関係を表しており、後者のリンクは「活性化エネルギー」が流れる重み付き経路を表していました。言うまでもなく、これら最初のコネクショニストネットワークは、各概念がニューロンのような単一のユニットにマッピングされていたため、論理的に強力なセマンティックネットワークに比べて表現能力を持っていませんでした。

さらに、局所的な表現スキームは、逐次的な情報を効率的に表現できません。標準的なアプローチでは、サブネットワークを複製して、逐次入力のために固定されたバッファのセットに時間を空間に変換する方法が使われます。

McClelland & Rumelhartの単語認識モデル[13]のような初期のコネクショニスト研究や、より現代的な取り組み[4, 14]もこのアプローチを使用していますが、これは事前に決められた長さ以上のシーケンスを表現または処理できません。

この長さの制限を克服する1つの方法は、入力をバッファ全体に「スライドさせる」ことです[15, 16]。そのようなシステムは、事前に決められた範囲を超えるシーケンスを処理することが可能ですが、それらを本当に表現しているわけではありません。

分散表現は、Hintonの1984年の報告[17]の流布以来、（ここで報告されている研究を含めて）多くの研究の焦点となっています。この報告では、「各エンティティは多くの計算要素に分散された活動のパターンによって表現され、各計算要素は多くの異なるエンティティの表現に関与する」といった表現の特性が議論されています。

最も明白で自然な分散表現は、言語学で伝統的に使用されている特徴（または微細特徴）システムです。このような表現を使用したコネクショニストモデルの良い例として、川本の語彙アクセスに関する研究[18]が挙げられます。

しかし、単一の概念を表現するためには、システム全体の特徴が必要であるため、これらの概念を含む構造を表現する試みは同じシステム内では管理できません。

例えば、すべての特徴が「看護師」を表現するために必要であり、すべての特徴が「象」を表現するために必要である場合、「看護師が象に乗る」という試みは、「白い象」や「4本足の大きな看護師」として表現されるかもしれません。

特徴の重ね合わせの問題を解決するために、エージェント、アクション、オブジェクトといったフルサイズの構成要素バッファを使用することが考えられます[5]。

各バッファには「看護師」「乗る」「象」といった役割を埋める特徴パターンが配置されます。しかし、構造全体の表現（連結による）と構造の要素（特徴による）の表現との二分法のため、このタイプのシステムでは、「ジョンが看護師が象に乗っているのを見た」といった埋め込み構造を表現することができません。

Hinton[19]によって予見されスケッチされた特徴バッファの二分法問題に対する解決策は、「看護師が象に乗る」ということに対する「縮約された説明」を用い、これが「ジョン」や「見た」といったパターンと共に構成要素バッファに収まるというものです。

しかし、そのような縮約された説明をどのように開発するかはすぐには明らかではありませんでした。代わりに、前衛的なコネクショニスト表現は粗符号化に基づいており[17]、これにより、複数の半独立な表現要素を重ね合わせによって特徴ベクトル内で同時に存在させることができます。複数の要素が存在できるようになると、それらの従来の要素のグループ化がより大きな構造として解釈されるようになります。

例えば、Touretzkyは粗符号化されたメモリシステムを開発し、それを生産システム[20]で使用しました。また、BoltzCONSという原始的なLISPデータ構造システム[21]や、簡単な木構造操作のために両者を組み合わせたもの[22]も利用しました。彼の表現では、25個のシンボル（A-Y）からなる15,625の三重項が表現され、それらを2000ビットを超えるパターンで使用することで、これらの三重項の小さなセットを確実に表現することができました。この三重項のセットを擬似CONSセルとして解釈することで、シーケンスや木構造の限られた表現が可能となりました。

同様に、過去形モデルにおいて、RumelhartとMcClelland[23]は、暗黙的に逐次的な表現（implicitly sequential representation）を開発しました。ここでは、一連の適切に形成された重なり合う三重項がシーケンスとして解釈されます。彼らの表現スキームの基本的なアイデアは、トークンのシーケンス $(i_1, \cdots, i_n)$ を、幅 $k$ のトークンの重なり合う部分シーケンスの無順序の集合としてエンコードするものとして見ることが参考になります。

$$
\{(i_1, \cdots, i_k), (i_2, \cdots, i_{k+1}), \cdots, (i_{n-k+1}, \cdots, i_n)\}
$$

したがって、もし粗符号化メモリがこのような部分シーケンスの集合を同時に表現できるなら、それはより長いシーケンスも表現できることになります。

この種類の表現の限界は、表現のコストがその幅に比例して指数関数的に増加することであり、特定の幅に対して、内部的な重複が多すぎるシーケンスが存在する可能性がある点です。集合は要素の複数回の出現を数えません。例えば、単語の綴りを文字のペアの集合として表現するシステムでは、「yoyo」という単語を表現することはできません。そして、幅を3に増やしたとしても、このシステムは「banana」のような重複する三重項を含む単語を表現することはできないでしょう。

TouretzkyとRumelhart & McClellandの粗符号化された表現は、それぞれの限られたタスクにおいてはかなり成功しましたが、いくつかの問題が残っています：

1. これらの表現の設計、圧縮、調整には多くの人間の労力が関わっており、その労力を他の領域にどのように適用するかが不明確なことが多い。
   
2. 粗符号化には、引き出しネットワーク[25]や節空間[20]のような高価で複雑なアクセス機構が必要です。
   
3. 粗符号化されたシンボルメモリは、表現要素（25トークンの三重項など）を同時に少数しか初期化できず、余計な要素が導入される前にすべての可能なトークンを組み合わせる必要があります。
   
4. それらは、大量のユニット（数百から数千）にわたって二進符号を利用します。
   
5. 基本要素から大きな構造を集約する彼らのモードは重ね合わせであり、問題(2)および(3)の原因となります。

対照的に、RAAMアーキテクチャによって考案された分散表現は、より優れた特性を示します：

1. エンコーディングはニューラルネットワークによって機械的に開発されます。

2. アクセスメカニズム（データや情報にどのようにアクセス（取得や操作）するかを指す概念です。この文脈では、RAAM（Recursive Auto-Associative Memory）アーキテクチャの中で、エンコーディングされた情報（分散表現）にアクセスし、データを取り出すための方法や手段を指しています）は単純で決定論的です。
   
3. 非常に多くのプリミティブ要素が選択的に構成要素構造に結合する可能性があります。すべてのシンボルの三重項が表現される、または表現される必要があるわけではありません。
   
4. 表現は、少数のユニット（数十）の上で実数値を利用します。
   
5. 集約モードは構成的です。

