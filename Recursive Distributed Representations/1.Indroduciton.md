# 1.Introduction

接続主義の高次認知タスク（自然言語処理など）への応用における主要な障害の一つは、その表現の不十分さです。

これまでのところ、局所的および分散された表現は、AIで伝統的に使用されてきた機構増や、グラフ、リスト、スタックのような階層的なデータ構造を捕捉するには不適切でした。

この制限は、純粋な接続主義がこの領域でやや満足のいかないシステムを生成した事実に現れています。

例えば、埋め込み構造なし（文の入れ子になった複雑な構造を扱えない）で固定長の文のパーサー（決まった長さの文だけを解析できるシステム）を生成するに留まっています。

実際、コネクショニズムに対する最近の攻撃のいくつかは、まさに表現の妥当性の問題に向けられています。

例えば、Minsky & Papert [10] によると、1970年代にAIが知識表現に焦点を当てなければならなくなった原因は、「少なくとも潜在的にXを表現するための内部構造やモデルを持たない限り、いかなる機械もXを認識できない」という原則によるものです (p. xiii)。」

Fodor と Pylyshyn [11] によるコネクショニズムに対する批判は、コネクショニズムがX（Xは構成要素の構造を持つ文法的なもの）の表現の潜在能力すら持っていないという信念に基づいています。
構成的なシンボル構造が重要であることに完全に同意した上で、この論文では、それらのためにコンパクトな分散表現を発見できるコネクショニストアーキテクチャを示します。

したがって、思考過程の（意味的な）「体系性」を示すことはできません。


RAAM は、非定常環境におけるバックプロパゲーション[12]を用いて、固定ヴァレンス木（各ノードが持つ子ノードの数（ヴァレンス、すなわち分岐の数）が一定である木構造です。）のすべての内部ノードを表すパターンを作り出します。

（バックプロパゲーションは訓練データが静的で固定されている前提で使用されますが、非定常環境では、データや条件が時間経過と共に変化し、ネットワークが新しい状況に適応する必要があります。このような環境では、モデルがその変化に対応できるように、動的に学習を続けることが求められる。）

＝RAAM（Recursive Auto-Associative Memory）は固定された状況ではなく、常に変化するデータや条件に対しても有効な表現パターンを学習することが目標

さらに、発見された表現は、単に古典的な連結型データ構造のコネクショニスト実装にとどまらず、実際には新しい、興味深い、そして潜在的に非常に有用なものです。

本論文の残りは以下のように構成されています。コネクショニスト表現スキームに関する背景を述べた後、RAAMアーキテクチャを説明し、いくつかの実験結果を提示します。最後に、このアーキテクチャの生成能力についての議論と、新しい表現およびその潜在的な応用に関する分析を行います。


# 1.1　Background: Connectionist Representations

通常のコンピュータプログラムは、配列やリストのような逐次データ構造を基本的な要素として長い間使用してきました。

さらに、これらのシーケンスの内容は他のシーケンスのアドレスになりうるという「アドレス」の概念が組み込まれているため、コンピュータプログラムが木構造やグラフ構造を表現し操作することも非常に簡単です。

しかし、リストや木構造を表現することはコネクショニストネットワークにとって簡単ではありません。

なぜなら、コネクショニストネットワークは隣接するメモリセルやランダムにアドレス指定されたメモリセルを使用せず、新しいユニットをリアルタイムで動的に作成することもできないからです。

現代のコネクショニズムにおける初期の研究のいくつかは、セマンティックネットワークとニューラルネットワークの間に不適切な類推を行いました。

（セマンティックネットワークは、概念間の論理的関係を表現するために使われる構造です。一方、ニューラルネットワークは、生物学的な脳の神経細胞を模倣して構築されており、重み付きのパス（経路）を通じて「活性化エネルギー」が流れる仕組みになっています。初期の研究では、これら二つのネットワークを同一視し、類似の仕組みだと考えられてしまうことがありました。

しかし、この類推は適切ではありませんでした。セマンティックネットワークは概念間の明示的な論理関係を扱うのに対し、ニューラルネットワークは重み付き経路を通じた非線形的な情報処理を行うものであり、基本的なメカニズムが大きく異なるからです。したがって、セマンティックネットワークとニューラルネットワークの違いを無視したり、過剰に類似性を主張することは不適切だったという意味になります。）


前者のリンクは概念間の論理的な関係を表しており、後者のリンクは「活性化エネルギー」が流れる重み付き経路を表していました。言うまでもなく、これら最初のコネクショニストネットワークは、各概念がニューロンのような単一のユニットにマッピングされていたため、論理的に強力なセマンティックネットワークに比べて表現能力を持っていませんでした。

さらに、局所的な表現スキームは、逐次的な情報を効率的に表現できません。標準的なアプローチでは、サブネットワークを複製して、逐次入力のために固定されたバッファのセットに時間を空間に変換する方法が使われます。McClelland & Rumelhartの単語認識モデル[13]のような初期のコネクショニスト研究や、より現代的な取り組み[4, 14]もこのアプローチを使用していますが、これは事前に決められた長さ以上のシーケンスを表現または処理できません。この長さの制限を克服する1つの方法は、入力をバッファ全体に「スライドさせる」ことです[15, 16]。そのようなシステムは、事前に決められた範囲を超えるシーケンスを処理することが可能ですが、それらを本当に表現しているわけではありません。

分散表現は、Hintonの1984年の報告[17]の流布以来、（ここで報告されている研究を含めて）多くの研究の焦点となっています。この報告では、「各エンティティは多くの計算要素に分散された活動のパターンによって表現され、各計算要素は多くの異なるエンティティの表現に関与する」といった表現の特性が議論されています。

最も明白で自然な分散表現は、言語学で伝統的に使用されている特徴（または微細特徴）システムです。このような表現を使用したコネクショニストモデルの良い例として、川本の語彙アクセスに関する研究[18]が挙げられます。しかし、単一の概念を表現するためには、システム全体の特徴が必要であるため、これらの概念を含む構造を表現する試みは同じシステム内では管理できません。例えば、すべての特徴が「看護師」を表現するために必要であり、すべての特徴が「象」を表現するために必要である場合、「看護師が象に乗る」という試みは、「白い象」や「4本足の大きな看護師」として表現されるかもしれません。

